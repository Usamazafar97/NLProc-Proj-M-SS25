# ğŸ“š Context-Aware Question Answering System

This project is a **retrieval-augmented generation (RAG)** pipeline that allows you to ask natural language questions based on custom documents (e.g., `.txt`, `.md`, `.pdf`). It uses:

* **Sentence Transformers + FAISS** for efficient document retrieval.
* **T5 (Flan-T5-Base)** for generating natural language answers.

---

## ğŸ“¦ Project Structure

```
.
â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ generator/
â”‚   â”‚   â””â”€â”€ generator.py        # T5 model to generate answer
â”‚   â””â”€â”€ retriever/
â”‚       â””â”€â”€ retriever.py        # Handles document parsing, chunking, embedding, FAISS retrieval
    â”œâ”€â”€ data/
        â”œâ”€â”€ logs.jsonl              # Stores question-answer logs
        â””â”€â”€ test_inputs.json        # Test questions
    â”œâ”€â”€ retriever_index/            # Saved index and metadata
    â”œâ”€â”€ pipeline.py                 # Main entry point

```

---

## âš™ï¸ Setup

1. **Install Dependencies:**

```txt
transformers
sentence-transformers
faiss-cpu
PyMuPDF
scikit-learn
torch
```

2. **Add Documents:**

Put `.pdf`, `.txt`, or `.md` files in the root or specific folder.

```python
retriever.add_documents(["myfile.pdf", "notes.txt"])
retriever.save()
```

3. **Test Questions:**

Add your questions to `data/test_inputs.json`:

```json
[
  {"question": "What is the purpose of this system?"},
  {"question": "Boeing ramp up production to how many aircraft?"}
]
```

---

## ğŸš€ Run the Pipeline

```bash
python pipeline.py
```

Output:

```bash
[0] Q: What is the purpose of this system?
    â¤ Answer: The system is designed to answer questions using document context.
    âœ… Grounded: True
```

---

## ğŸ“ Features

* âœ… Handles `.pdf`, `.txt`, and `.md` files
* ğŸ” FAISS indexing for fast similarity search
* âœ‚ï¸ Text chunking for efficient context management
* ğŸ§  T5-based generation
* ğŸ“ Logs all interactions in `logs.jsonl`

---

## ğŸ§ª Evaluation

Each answer is considered **grounded** if it contains a portion from any of the top-3 retrieved chunks.

---

## ğŸ“Š Sample Log Entry

```json
{
  "timestamp": "2025-05-21T15:30:00Z",
  "group_id": "Team_Turing",
  "question": "What is the main use of FAISS?",
  "retrieved_chunks": ["FAISS is used for efficient similarity search."],
  "prompt": "Context:\nFAISS is used for efficient similarity search.\n\nQuestion: What is the main use of FAISS?\nAnswer:",
  "generated_answer": "FAISS is mainly used for efficient similarity search."
}
```

---

## ğŸ“¬ Future Improvements

* Switch to **LlamaIndex or LangChain** for advanced pipelines
* Add **feedback loop** to fine-tune answers
* Improve UI for non-technical users

---

Made with â¤ï¸ by Team Turing
